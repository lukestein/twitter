<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<title>lukesteinâ€™s Twitter Archiveâ€”â„– 16,101</title>
		<meta name="description" content="@McaleerStephen @drjwrae This is cool. Got me thinking that maybe LLM weights are â€œlossy â€˜compressionâ€™â€ of training data in some ways like how 10,000 pages of the Journal of Shakespeare Studies is a lossy compression of Shakespeareâ€™s 1300-page collected works.">

		<link rel="profile" href="https://microformats.org/profile/hatom">
		<link rel="stylesheet" href="/twitter/assets/style.css">
		<script src="/twitter/assets/script.js" type="module"></script>
		<script src="/twitter/assets/is-land.js" type="module"></script>

		
	</head>
	<body>
		<header>
			<h1 class="tweets-title"><a href="/twitter/"><img src="https://lukestein.github.io/profilepics/lukestein_split_16.png" width="52" height="52" alt="lukesteinâ€™s avatar" class="tweet-avatar">lukesteinâ€™s Twitter Archive</a>â€”â„– 16,101</h1>
			
			<ul class="tweets-nav">
			<li><a href="/twitter/newest/">â‡¤ Newest<span class="sr-only"> Tweet</span></a></li>
			<li><a href="/twitter/1704935662883856875/">â‡  Newer<span class="sr-only"> Tweet</span></a></li>
			<li><a href="/twitter/1704848482421313657/">Older<span class="sr-only"> Tweet</span> â‡¢</a></li>
		</ul>
		</header>
		<main>
			<ol class="tweets tweets-thread h-feed hfeed" data-pagefind-body="">
			
			<li id="1704928091087286685" class="tweet h-entry is_reply " data-pagefind-index-attrs="id">
		<a href="https://twitter.com/McaleerStephen/status/1704892210511303060" class="tweet-pretext u-in-reply-to">â€¦in reply to @McaleerStephen</a>
			<div class="tweet-text e-content" data-pagefind-body=""><a href="https://twitter.com/McaleerStephen/" class="tweet-username h-card">@<span class="p-nickname">McaleerStephen</span></a> <a href="https://twitter.com/drjwrae/" class="tweet-username h-card">@<span class="p-nickname">drjwrae</span></a> This is cool. Got me thinking that maybe LLM weights are â€œlossy â€˜compressionâ€™â€ of training data in some ways like how 10,000 pages of the Journal of Shakespeare Studies is a lossy compression of Shakespeareâ€™s 1300-page collected works.</div>
			<span class="tweet-metadata">
				
				<a href="https://twitter.com/lukestein/status/1704928091087286685" class="tag tag-icon u-url" data-pagefind-index-attrs="href"><span class="sr-only">On twitter.com </span><img src="https://v1.indieweb-avatar.11ty.dev/https%3A%2F%2Fx.com%2F/" alt="Twitter logo" width="27" height="27"></a>
				
				<a href="/twitter/" class="tag tag-naked tag-lite tag-avatar"><img src="https://lukestein.github.io/profilepics/lukestein_split_16.png" width="52" height="52" alt="lukesteinâ€™s avatar" class="tweet-avatar"></a>
				<span class="tag tag-lite tag-favorite">â¤ï¸ 1<span class="sr-only"> Favorite</span></span>
				<time class="tag tag-naked tag-lite dt-published" datetime="2023-09-21T18:38:27.000Z">2023 Sep 21</time>
				<span class="tag tag-naked tag-lite sr-only">Mood +<strong class="tweet-sentiment">3</strong> ğŸ™‚</span>
			</span>
		</li>
			
		</ol>
		</main>
		<footer>
			<p>An open source project from <a href="https://github.com/tweetback">tweetback</a>.</p>
		</footer>
	</body>
</html>